# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a5yUEilMeU630uLhzbMCTeVXJHG0Y067

# K-NN- K-Nearest-Neighbors

### Feito por: Jonathas Luis de Sousa
### GCC128-Inteligência Artificial
### Turma 14A

## Carregamento e tratamento do Dataset

Nesta seção se encontra a importação das bibliotecas, inclusive o dataset Iris, direto da biblioteca sklearn.

Além disso, é mostrado alguns metadados do dataset, que alguns auxiliará nos parâmetros do kmeans.

Além do mais, o dataset é convertido em uma etrutura de dados mais simples de ser trabalhada, no caso as listas.

Bibliotecas / Pacotes utilizadas:
  - **sklearn -> datasets:** pacote em que se encontra datasets para estudo de ML;
  - **sklearn.model_selection -> train_test_split:** pacote para dividir arrays ou matrizes em subconjuntos aleatórios de treinamento e teste.
  - **pandas:** biblioteca de manipulação e análise de dados;
  - **matplotlib -> pyplot:** biblioteca para a vizualização gráfica dos dados;
  - **scipy.spatial -> distance:** biblioteca com funções de calculos de distâncias;
  - **numpy:** pacote com uma grande coleção de funções matemáticas
  - **collections -> counter:** módulo utilizado para facilitar a contagem de elemetos em estruturas de dados.
  - **sklearn -> metrics:** módulo para facilitar os calculos das métricas.
"""

from sklearn import datasets
from sklearn.model_selection import train_test_split
import pandas as pd
from matplotlib import pyplot as plt
from scipy.spatial import distance
import numpy as np
from collections import Counter
from sklearn import metrics

# carregamento do dataset iris do sklean
iris = datasets.load_iris()
iris_df=pd.DataFrame(iris.data)
iris_df["classe"] = iris.target
iris_df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid','classe']

iris_df.head()

#informações sobre dataFrame
print(iris_df.shape, '\n')
print(iris_df.columns,'\n')
print(iris_df.dtypes)

# estatisticas dos dados
iris_df.describe()

x= iris_df.iloc[:, :-1]
y= iris_df.iloc[:, -1]

"""## Algoritmo

### Funções Auxiliares
"""

#calcula a distancia euclidiana entre dois pontos, considerando todas as colunas / dimensões
def distanciaEuclidiana(p1,p2):
  return distance.euclidean(p1,p2)

# calcula a distancia entre um ponto e todos os outros pontos
def listaDeDistancias(listaDePontos,ponto):
  distancias = []
  size = len(listaDePontos)
  for i in range(size):
    pontoAtual = listaDePontos[i]
    distanciaAtual = distanciaEuclidiana(pontoAtual,ponto)
    distancias.append(distanciaAtual)
  return distancias

# retorna os K pontos mais proximos de um ponto
def vizinhosMaisProximos(listaDeDistanciasDoPonto,k):
  return np.argsort(listaDeDistanciasDoPonto)[:k].tolist()

# retorna a classe que mais aparece dentre os k vizinhos mais proximos
def predicao(knn,labels):
  count = Counter(labels[knn])
  return count.most_common()[0][0]

"""### K-NN"""

def KNN(xTreino,yTreino,xTeste,k):
  pred = []

  for pontoXTeste in xTeste:
    distancia = listaDeDistancias(xTreino,pontoXTeste)
    knn = vizinhosMaisProximos(distancia,k)
    yPred = predicao(knn,yTreino)
    pred.append(yPred)

  return pred

# divisão em treino e teste
nroVizinhos = [1,2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
qtdTeste = 0.40
xTreino, xTeste, yTreino, yTeste = train_test_split(x,y,test_size=qtdTeste,shuffle=True,random_state=0)

confusions = []
accuracies = []
for k in nroVizinhos:
  pred = KNN(xTreino.values, yTreino.values, xTeste.values, k)
  print("k =",k)
  print(pred)
  confusions.append(metrics.confusion_matrix(yTeste.values, pred))
  accuracies.append(metrics.accuracy_score(yTeste.values, pred))
  print("\n")
  print(metrics.classification_report(yTeste.values, pred))

confusions

accuracies

"""## Visualização"""

plt.plot(nroVizinhos, accuracies, marker='o')
plt.title('Impacto do valor de K na taxa de reconhecimento')
plt.xlabel('k')
plt.ylabel('Acurácia')
plt.grid(True)
plt.show()